{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の手順\n",
    "### 前提\n",
    "    - ニューラルネットワークは，適用可能な重みとバイアスがあり，\n",
    "    この重みとバイアスを訓練データに適応するように調整することを\n",
    "    「学習\u001d",
    "」と呼ぶ．\u001f\n",
    "### ステップ1（ミニバッチ）\n",
    "    - 訓練データの中からランダムに一部のデータを選び出す．\n",
    "### ステップ2（勾配の算出）\n",
    "    - \bミニバッチの損失関数を減らすために，各重みパラメータの勾配を\b求める．\n",
    "    勾配は，\b損失関数の\b値を減少させる\b方向を示す．\n",
    "### ステップ3（パラメータを更新）\n",
    "    - 重みパラメータを勾配方向へ微小量だけ更新する．\n",
    "### ステップ4（繰り返す）\n",
    "    - ステップ 1〜3 を繰り返す．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x-h))/(2*h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1,5))\n",
    "print(numerical_diff(function_1,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偏微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0**2 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1**2\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1-fxh2)/(2*h)\n",
    "        x[idx] = tmp_val\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0,4.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0,0.0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2,\n",
    "                 np.array([-3.0, 4.0]),\n",
    "                 lr = 0.1,\n",
    "                 step_num=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークに対する勾配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16283879  0.08235172 -0.24519051]\n",
      " [ 0.24425818  0.12352759 -0.36778577]]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "t = np.array([0, 0, 1])\n",
    "\n",
    "net = simpleNet()\n",
    "\n",
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "\n",
    "print(dW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層ニューラルネットワークのクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        dz1 = np.dot(dy, W2.T)\n",
    "        da1 = sigmoid_grad(a1) * dz1\n",
    "        grads['W1'] = np.dot(x.T, da1)\n",
    "        grads['b1'] = np.sum(da1, axis=0)\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784\n",
    "                 ,hidden_size=100\n",
    "                 ,output_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net.predict(np.random.rand(100,784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.11236666666666667, 0.1135\n",
      "train acc, test acc | 0.7855166666666666, 0.7881\n",
      "train acc, test acc | 0.8764, 0.8783\n",
      "train acc, test acc | 0.8988166666666667, 0.9004\n",
      "train acc, test acc | 0.9082666666666667, 0.9101\n",
      "train acc, test acc | 0.9155166666666666, 0.9148\n",
      "train acc, test acc | 0.9185833333333333, 0.9195\n",
      "train acc, test acc | 0.9236666666666666, 0.925\n",
      "train acc, test acc | 0.9279833333333334, 0.93\n",
      "train acc, test acc | 0.9312333333333334, 0.9333\n",
      "train acc, test acc | 0.935, 0.9362\n",
      "train acc, test acc | 0.93725, 0.9375\n",
      "train acc, test acc | 0.9387, 0.9393\n",
      "train acc, test acc | 0.9412666666666667, 0.9421\n",
      "train acc, test acc | 0.9438833333333333, 0.9437\n",
      "train acc, test acc | 0.9450666666666667, 0.9455\n",
      "train acc, test acc | 0.9468166666666666, 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d4386a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000  # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10652c048>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.1.1]",
   "language": "python",
   "name": "conda-env-anaconda3-4.1.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipythonP",
  "version": "Python 3.5.2 :: Anaconda custom (x86_64)"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
